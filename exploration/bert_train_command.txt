python3.6 ./repos/transformers/examples/run_language_modeling.py --train_data_file=./data/train.txt --eval_data_file=./data/test.txt --output_dir=./bert/ --tokenizer_name=./data/hebrew-vocab.txt --mlm --do_train --do_eval --model_type=bert --per_gpu_train_batch_size=8 --per_gpu_eval_batch_size=8 --line_by_line --num_train_epochs=15 --save_total_limit=3 --save_steps=5000