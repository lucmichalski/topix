{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-large-uncased-whole-word-masking'\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "logsm = nn.LogSoftmax()\n",
    "logsm = logsm.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(seq: str, masked_indexes=None):\n",
    "    tokenized_text = tokenizer.tokenize(seq)\n",
    "    if masked_indexes is None:\n",
    "        if \"[MASK]\" not in tokenized_text:\n",
    "            raise Exception(\"[MASK] token not in input\")\n",
    "        masked_indexes = indices = [i for i, x in enumerate(tokenized_text) if x == \"[MASK]\"]\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "    return predictions[0, masked_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4119, -5.4709, -6.2785,  ..., -4.6543, -5.6838, -4.9877]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(\"[CLS] I love eating fruits such as [MASK] [SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_list(predictions):\n",
    "    results = []\n",
    "    for pred in predictions:\n",
    "        predicted_indexes = list(torch.argsort(pred))[::-1]\n",
    "        predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indexes)\n",
    "        predicted_probs = logsm(pred[predicted_indexes])\n",
    "        results.append(list(zip(predicted_tokens, predicted_probs, pred[predicted_indexes])))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(seq: str, limit: int, masked_index=None):\n",
    "    for pred in predictions_to_list(get_predictions(seq, masked_index)):\n",
    "        for token, prob, p in pred[:limit]:\n",
    "            print(f\"token: {token}\\t log probability: {prob}\\t p: {p}\")\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: fruit\t log probability: -1.031285285949707\t p: 15.024468421936035\n",
      "token: plant\t log probability: -1.5805988311767578\t p: 14.475154876708984\n",
      "token: vegetable\t log probability: -2.7677001953125\t p: 13.288053512573242\n",
      "token: flower\t log probability: -3.0948991775512695\t p: 12.960854530334473\n",
      "token: tree\t log probability: -3.323002815246582\t p: 12.73275089263916\n",
      "token: seed\t log probability: -3.6802635192871094\t p: 12.375490188598633\n",
      "token: cereal\t log probability: -3.6965322494506836\t p: 12.359221458435059\n",
      "token: fungus\t log probability: -3.8061017990112305\t p: 12.249651908874512\n",
      "token: grain\t log probability: -3.8994436264038086\t p: 12.156310081481934\n",
      "token: food\t log probability: -4.320439338684082\t p: 11.73531436920166\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sentence = \"[CLS] apple is a [MASK] . [SEP]\"\n",
    "print_predictions(sentence, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: weekdays\t log probability: -2.153414726257324\t p: 12.686539649963379\n",
      "token: sunday\t log probability: -2.1941633224487305\t p: 12.645791053771973\n",
      "token: sundays\t log probability: -2.382669448852539\t p: 12.457284927368164\n",
      "token: holidays\t log probability: -2.4000444412231445\t p: 12.439909934997559\n",
      "token: monday\t log probability: -2.827853202819824\t p: 12.012101173400879\n",
      "token: saturday\t log probability: -2.838412284851074\t p: 12.001542091369629\n",
      "token: weekends\t log probability: -2.953669548034668\t p: 11.886284828186035\n",
      "token: weekday\t log probability: -3.213428497314453\t p: 11.62652587890625\n",
      "token: friday\t log probability: -3.275822639465332\t p: 11.564131736755371\n",
      "token: fridays\t log probability: -3.424633026123047\t p: 11.415321350097656\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sentence = \"[CLS] [MASK], such as saturday and friday [SEP]\"\n",
    "print_predictions(sentence, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: pop\t log probability: -1.2998237609863281\t p: 12.097662925720215\n",
      "token: popular\t log probability: -2.0287046432495117\t p: 11.368782043457031\n",
      "token: rock\t log probability: -2.095531463623047\t p: 11.301955223083496\n",
      "token: musical\t log probability: -3.063312530517578\t p: 10.334174156188965\n",
      "token: famous\t log probability: -3.370610237121582\t p: 10.026876449584961\n",
      "token: music\t log probability: -3.593216896057129\t p: 9.804269790649414\n",
      "token: celebrity\t log probability: -3.9175596237182617\t p: 9.479927062988281\n",
      "token: notable\t log probability: -4.284005165100098\t p: 9.113481521606445\n",
      "token: superstar\t log probability: -4.489748001098633\t p: 8.90773868560791\n",
      "token: mainstream\t log probability: -4.56675910949707\t p: 8.830727577209473\n",
      "----\n",
      "token: artists\t log probability: -1.5210762023925781\t p: 12.927189826965332\n",
      "token: musicians\t log probability: -1.8203630447387695\t p: 12.62790298461914\n",
      "token: music\t log probability: -2.247682571411133\t p: 12.200583457946777\n",
      "token: icons\t log probability: -2.818789482116699\t p: 11.629476547241211\n",
      "token: stars\t log probability: -2.884380340576172\t p: 11.563885688781738\n",
      "token: performers\t log probability: -3.083620071411133\t p: 11.364645957946777\n",
      "token: acts\t log probability: -3.246434211730957\t p: 11.201831817626953\n",
      "token: figures\t log probability: -3.5058135986328125\t p: 10.942452430725098\n",
      "token: celebrities\t log probability: -3.8578643798828125\t p: 10.590401649475098\n",
      "token: ##s\t log probability: -3.990753173828125\t p: 10.457512855529785\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sentence = \"[CLS] [MASK] [MASK], such as elvis and the beatles [SEP]\"\n",
    "print_predictions(sentence, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: the\t log probability: -3.1562976837158203\t p: 9.283946990966797\n",
      "token: michael\t log probability: -3.59041690826416\t p: 8.849827766418457\n",
      "token: david\t log probability: -3.74137020111084\t p: 8.698874473571777\n",
      "token: james\t log probability: -4.008335113525391\t p: 8.431909561157227\n",
      "token: neil\t log probability: -4.092800140380859\t p: 8.347444534301758\n",
      "token: billy\t log probability: -4.180458068847656\t p: 8.259786605834961\n",
      "token: george\t log probability: -4.258735656738281\t p: 8.181509017944336\n",
      "token: tom\t log probability: -4.492015361785889\t p: 7.9482293128967285\n",
      "token: elton\t log probability: -4.507739067077637\t p: 7.9325056076049805\n",
      "token: bryan\t log probability: -4.555271148681641\t p: 7.884973526000977\n",
      "----\n",
      "token: jackson\t log probability: -3.8180456161499023\t p: 8.245426177978516\n",
      "token: adams\t log probability: -4.385303020477295\t p: 7.678168773651123\n",
      "token: williams\t log probability: -4.399244785308838\t p: 7.66422700881958\n",
      "token: springsteen\t log probability: -4.633245468139648\t p: 7.4302263259887695\n",
      "token: brown\t log probability: -4.697864055633545\t p: 7.365607738494873\n",
      "token: dylan\t log probability: -4.804352283477783\t p: 7.259119510650635\n",
      "token: sinatra\t log probability: -4.866396903991699\t p: 7.197074890136719\n",
      "token: springfield\t log probability: -4.867153167724609\t p: 7.196318626403809\n",
      "token: west\t log probability: -4.899347305297852\t p: 7.164124488830566\n",
      "token: stewart\t log probability: -4.945705890655518\t p: 7.1177659034729\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sentence = '[CLS] \"let it be\", \"strawberry fields forever\" and \"I wanna hold your hand\" are songs by [MASK] [MASK] . [SEP]'\n",
    "print_predictions(sentence, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: \"\t log probability: -1.9399681091308594\t p: 13.210062026977539\n",
      "token: ##י\t log probability: -2.0456180572509766\t p: 13.104412078857422\n",
      "token: ##ו\t log probability: -2.2604904174804688\t p: 12.88953971862793\n",
      "token: ##ד\t log probability: -2.605360984802246\t p: 12.544669151306152\n",
      "token: ##ל\t log probability: -2.8682384490966797\t p: 12.281791687011719\n",
      "token: ##נ\t log probability: -3.020265579223633\t p: 12.129764556884766\n",
      "token: ##מ\t log probability: -3.2315244674682617\t p: 11.918505668640137\n",
      "token: ##פ\t log probability: -3.300172805786133\t p: 11.849857330322266\n",
      "token: ##ת\t log probability: -3.436406135559082\t p: 11.713624000549316\n",
      "token: ##ר\t log probability: -3.470670700073242\t p: 11.679359436035156\n",
      "----\n",
      "token: ##ה\t log probability: -1.3304805755615234\t p: 14.118085861206055\n",
      "token: ##ת\t log probability: -1.6360149383544922\t p: 13.812551498413086\n",
      "token: ##ו\t log probability: -2.020946502685547\t p: 13.427619934082031\n",
      "token: ##ם\t log probability: -2.962373733520508\t p: 12.48619270324707\n",
      "token: ##י\t log probability: -3.0785560607910156\t p: 12.370010375976562\n",
      "token: ##ך\t log probability: -3.5643253326416016\t p: 11.884241104125977\n",
      "token: ##ן\t log probability: -4.182732582092285\t p: 11.265833854675293\n",
      "token: ##ש\t log probability: -4.208676338195801\t p: 11.239890098571777\n",
      "token: ו\t log probability: -4.243732452392578\t p: 11.204833984375\n",
      "token: ל\t log probability: -4.321378707885742\t p: 11.127187728881836\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sentence = '[CLS] דמויות מהתנ\"ך, כמו [MASK][MASK], היו דמויות מרכזיות בתקופת ממלכת יהודה. [SEP]'\n",
    "print_predictions(sentence, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
